{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0744de",
   "metadata": {},
   "source": [
    "# Name: Sakshi Deokar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22fe4d",
   "metadata": {},
   "source": [
    "# Library: Pytables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d9fb1",
   "metadata": {},
   "source": [
    "URL: https://www.pytables.org/usersguide/tutorials.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82960180",
   "metadata": {},
   "source": [
    "# Description: \n",
    "PyTables is a Python library that efficiently manages large datasets using the HDF5 format. It optimizes storage space, speeds up data access, and supports compression, making it ideal for handling complex data structures and large volumes of information in various fields, including science, engineering, finance, and analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d2228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (3.8.0)\r\n",
      "Requirement already satisfied: cython>=0.29.21 in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (3.0.10)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (1.24.3)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (2.8.4)\r\n",
      "Requirement already satisfied: blosc2~=2.0.0 in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (2.0.0)\r\n",
      "Requirement already satisfied: packaging in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (23.1)\r\n",
      "Requirement already satisfied: py-cpuinfo in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from tables) (8.0.0)\r\n",
      "Requirement already satisfied: msgpack in /Users/sakshideokar/anaconda3/lib/python3.11/site-packages (from blosc2~=2.0.0->tables) (1.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd4e13",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install PyTables using pip to manage HDF5 file formats efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b233b",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Import necessary Python libraries for handling data and working with HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9a6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTables for handling HDF5 files and pandas for data manipulation\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827e9b4",
   "metadata": {},
   "source": [
    "### Data Definition and HDF5 File Creation\n",
    "\n",
    "Define a data structure for storing sales data and create an HDF5 file to hold this data. This step involves:\n",
    "- Defining a Python class to structure the sales data.\n",
    "- Creating an HDF5 file and a table within it for data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300fd326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to represent sales data\n",
    "class Sales(tb.IsDescription):\n",
    "    transaction_date = tb.StringCol(10)  # Date of transaction (formatted as YYYY-MM-DD)\n",
    "    product_id = tb.StringCol(10)        # Product identifier\n",
    "    quantity_sold = tb.IntCol()          # Quantity of product sold\n",
    "    sales_amount = tb.FloatCol()         # Total sales amount for the transaction\n",
    "\n",
    "# Create an HDF5 file and a table within it to store sales data\n",
    "h5file = tb.open_file(\"sales_data.h5\", mode=\"w\", title=\"Sales Data\")\n",
    "sales_table = h5file.create_table(\"/\", \"sales\", Sales, \"Sales Data Table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055f310",
   "metadata": {},
   "source": [
    "### Data Insertion and Flushing to Disk\n",
    "\n",
    "Insert sample sales data into the HDF5 table and flush the data to ensure it's written to the file. This involves:\n",
    "- Adding data to the table row by row.\n",
    "- Flushing the table's buffer to write changes to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdc89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Get a reference to the sales table\n",
    "sales = h5file.root.sales\n",
    "\n",
    "# Insert sample sales data into the table\n",
    "sales_row = sales.row\n",
    "sales_row['transaction_date'] = '2024-04-17'  # Set transaction date\n",
    "sales_row['product_id'] = 'P001'              # Set product ID\n",
    "sales_row['quantity_sold'] = 10               # Set quantity sold\n",
    "sales_row['sales_amount'] = 100.0             # Set sales amount\n",
    "sales_row.append()                            # Add the record to the table\n",
    "\n",
    "# Repeat insertion for another product\n",
    "sales_row['transaction_date'] = '2024-04-17'\n",
    "sales_row['product_id'] = 'P002'\n",
    "sales_row['quantity_sold'] = 5\n",
    "sales_row['sales_amount'] = 50.0\n",
    "sales_row.append()\n",
    "\n",
    "# Flush the data to disk to ensure it is written to the file\n",
    "sales.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d66b4",
   "metadata": {},
   "source": [
    "# Calculate Total Sales for a Specific Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925cd625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales for 2024-04-17: 150.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function to query total sales amount for a given date\n",
    "def get_total_sales_for_date(transaction_date):\n",
    "    query = (f\"transaction_date == '{transaction_date}'\")\n",
    "    result = sales.read_where(query)\n",
    "    total_sales = result['sales_amount'].sum()\n",
    "    return total_sales\n",
    "\n",
    "# Get total sales amount for a specific date\n",
    "total_sales = get_total_sales_for_date('2024-04-17')\n",
    "print(\"Total Sales for 2024-04-17:\", total_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be76e1",
   "metadata": {},
   "source": [
    "# Advanced Data Manipulation and AnalysisÂ¶\n",
    "Further develop the data manipulation and analysis capabilities by:\n",
    "\n",
    "Extending the data model with additional fields.\n",
    "Generating a larger dataset.\n",
    "Defining and using a function to calculate rolling averages of sales data based on specific criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "711a086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define a class to represent sales data with additional fields\n",
    "class SalesAdvanced(tb.IsDescription):\n",
    "    transaction_date = tb.StringCol(10)\n",
    "    store_id = tb.StringCol(10)\n",
    "    city = tb.StringCol(20)\n",
    "    product_id = tb.StringCol(10)\n",
    "    product_category = tb.StringCol(20)\n",
    "    quantity_sold = tb.IntCol()\n",
    "    sales_amount = tb.FloatCol()\n",
    "\n",
    "# Create an HDF5 file and a table within it to store sales data\n",
    "h5file_advanced = tb.open_file(\"sales_data_advanced.h5\", mode=\"w\", title=\"Advanced Sales Data\")\n",
    "sales_table_advanced = h5file_advanced.create_table(\"/\", \"sales_advanced\", SalesAdvanced, \"Advanced Sales Data Table\")\n",
    "\n",
    "# Generate sample sales data\n",
    "np.random.seed(0)\n",
    "dates = np.random.choice(pd.date_range('2020-01-01', '2023-12-31'), size=10000)\n",
    "store_ids = np.random.choice(['S001', 'S002', 'S003'], size=10000)\n",
    "cities = np.random.choice(['New York', 'London', 'Tokyo'], size=10000)\n",
    "product_ids = np.random.choice(['P001', 'P002', 'P003'], size=10000)\n",
    "product_categories = np.random.choice(['Electronics', 'Clothing', 'Home Decor'], size=10000)\n",
    "quantities_sold = np.random.randint(1, 100, size=10000)\n",
    "sales_amounts = np.random.uniform(10, 1000, size=10000)\n",
    "\n",
    "# Insert sample sales data into the table\n",
    "sales_row_advanced = sales_table_advanced.row\n",
    "for i in range(len(dates)):\n",
    "    date_str = pd.to_datetime(dates[i]).strftime('%Y-%m-%d')  # Convert and format date\n",
    "    sales_row_advanced['transaction_date'] = date_str\n",
    "    sales_row_advanced['store_id'] = store_ids[i]\n",
    "    sales_row_advanced['city'] = cities[i]\n",
    "    sales_row_advanced['product_id'] = product_ids[i]\n",
    "    sales_row_advanced['product_category'] = product_categories[i]\n",
    "    sales_row_advanced['quantity_sold'] = quantities_sold[i]\n",
    "    sales_row_advanced['sales_amount'] = sales_amounts[i]\n",
    "    sales_row_advanced.append()\n",
    "\n",
    "# Flush the data to disk and close the file\n",
    "sales_table_advanced.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caaa5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy datetime object to Python datetime object before formatting\n",
    "dates_python = [date.astype('M8[D]').astype('O') for date in dates]\n",
    "\n",
    "\n",
    "# Insert sample sales data into the table\n",
    "sales_row_advanced = sales_table_advanced.row\n",
    "for i in range(len(dates)):\n",
    "    sales_row_advanced['transaction_date'] = dates_python[i].strftime('%Y-%m-%d')\n",
    "    sales_row_advanced['store_id'] = store_ids[i]\n",
    "    sales_row_advanced['city'] = cities[i]\n",
    "    sales_row_advanced['product_id'] = product_ids[i]\n",
    "    sales_row_advanced['product_category'] = product_categories[i]\n",
    "    sales_row_advanced['quantity_sold'] = quantities_sold[i]\n",
    "    sales_row_advanced['sales_amount'] = sales_amounts[i]\n",
    "    sales_row_advanced.append()\n",
    "\n",
    "# Flush the data to disk\n",
    "sales_table_advanced.flush()\n",
    "h5file_advanced.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "933a5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'London', b'Home Decor', b'P001', 3, 409.73509426, b'S002', b'2021-11-15'), (b'London', b'Clothing', b'P003', 80, 564.15181473, b'S002', b'2021-07-13'), (b'New York', b'Home Decor', b'P003', 16, 835.35314682, b'S002', b'2023-05-01'), (b'London', b'Home Decor', b'P002', 56, 343.57815543, b'S001', b'2022-04-15'), (b'Tokyo', b'Home Decor', b'P003', 75, 76.69610362, b'S002', b'2022-02-02'), (b'New York', b'Electronics', b'P001', 92, 81.34099112, b'S003', b'2023-10-15'), (b'Tokyo', b'Electronics', b'P002', 34, 344.48207346, b'S003', b'2022-10-30'), (b'London', b'Home Decor', b'P002', 46, 257.93702239, b'S001', b'2020-10-04'), (b'London', b'Electronics', b'P001', 85, 180.24478043, b'S001', b'2021-08-22'), (b'Tokyo', b'Home Decor', b'P001', 50, 286.59070769, b'S001', b'2022-12-30')]\n"
     ]
    }
   ],
   "source": [
    "#to read and verify that the data was stored correctly\n",
    "with tb.open_file(\"sales_data_advanced.h5\", mode=\"r\") as file:\n",
    "    table = file.root.sales_advanced\n",
    "    data = [row.fetch_all_fields() for row in table.iterrows()]\n",
    "    print(data[:10])  # Print the first 10 records to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
